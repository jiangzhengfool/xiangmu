{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入必备工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'dataset'\n",
    "encodings = 'encodings.pickle'\n",
    "detection_method = 'cnn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取到所有输入数据的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_files(basePath):\n",
    "    for (rootDir,dirName,filenames) in os.walk(basePath):\n",
    "        for filename in filenames:\n",
    "            imagePath = os.path.join(rootDir,filename)\n",
    "            yield imagePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagePaths = list(list_files(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对图像进行编码，转换成128D的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前输入数据索引 0\n",
      "当前输入数据索引 1\n",
      "当前输入数据索引 2\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for (i,imagePath) in enumerate(imagePaths):\n",
    "    print ('当前输入数据索引',i)\n",
    "    #读取到图像数据\n",
    "    image = cv2.imread(imagePath)\n",
    "    #转换下顺序，因为一会要用工具包进行人脸检测，所以所必须得是固定格式\n",
    "    rgb = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    #人脸检测\n",
    "    boxes = face_recognition.face_locations(rgb,model=detection_method)\n",
    "    #向量编码\n",
    "    encodings = face_recognition.face_encodings(rgb,boxes)\n",
    "    #组合得到的结果\n",
    "    d = [{'imagePath':imagePath,'loc':box,'encoding':enc} for (box,enc) in zip(boxes,encodings)]\n",
    "    data.extend(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(encodings,'wb')\n",
    "f.write(pickle.dump(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取保存好的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.loads(open(encodings,'rb').read())\n",
    "data = np.array(data)\n",
    "encodings = [d['encoding'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13456686,  0.14403877,  0.07261265, -0.02214705, -0.13693842,\n",
       "        0.00447783,  0.04457019, -0.10250483,  0.19053376, -0.01216701,\n",
       "        0.27943072, -0.05122857, -0.22868238, -0.05441248, -0.05913119,\n",
       "        0.10733175, -0.17733857, -0.12875885, -0.0175312 , -0.00771059,\n",
       "        0.042868  ,  0.03457959,  0.0113402 ,  0.06657487, -0.12548007,\n",
       "       -0.34815612, -0.04874776, -0.1136909 ,  0.08474787, -0.08733188,\n",
       "       -0.03128369,  0.05843937, -0.2168265 , -0.08472218, -0.00858918,\n",
       "        0.03199864, -0.00700156, -0.06248249,  0.20330036,  0.02258976,\n",
       "       -0.15130012,  0.03175352, -0.01839004,  0.31603727,  0.09881824,\n",
       "       -0.00549249,  0.05976491, -0.10961753,  0.07141068, -0.1757232 ,\n",
       "        0.08242613,  0.2088591 ,  0.11992976,  0.02375047, -0.02019374,\n",
       "       -0.13702856,  0.01252095,  0.12100402, -0.23836303,  0.13112594,\n",
       "        0.13510659, -0.00267247,  0.03402919, -0.01406269,  0.17453504,\n",
       "        0.09060631, -0.03872195, -0.15619071,  0.14142843, -0.10484159,\n",
       "       -0.06705774,  0.02236612, -0.16135284, -0.21844624, -0.24592766,\n",
       "        0.0939405 ,  0.41721529,  0.15937674, -0.1962689 ,  0.01833584,\n",
       "       -0.15175611, -0.02472411,  0.09291548,  0.03777162, -0.06885795,\n",
       "       -0.03783436, -0.16184196,  0.07231899,  0.20655479, -0.00769841,\n",
       "       -0.05761547,  0.22821409,  0.0430321 , -0.0599584 ,  0.02972405,\n",
       "        0.02454992, -0.09605417,  0.07196116, -0.11113134, -0.01760821,\n",
       "        0.02204115, -0.06669358,  0.0146875 ,  0.13285762, -0.22083615,\n",
       "        0.13210346,  0.01850311, -0.0380832 , -0.01844689,  0.00199955,\n",
       "       -0.09730388, -0.04405926,  0.15125886, -0.21122853,  0.26302302,\n",
       "        0.14146633,  0.088265  ,  0.16499896,  0.04976539,  0.04775391,\n",
       "        0.03530201, -0.03458301, -0.09015308, -0.07108042,  0.06861186,\n",
       "       -0.0074924 ,  0.0923935 ,  0.06040892])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(encodings).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行聚类操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=0.5, leaf_size=30, metric='euclidean',\n",
       "    metric_params=None, min_samples=5, n_jobs=-1, p=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan = DBSCAN(metric = 'euclidean',n_jobs=-1)\n",
    "dbscan.fit(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  1,  0,  2,  3,  1,  0,  2,  0,  3,  0,  1,  0,  0,  4,  0,\n",
       "        2,  1,  4,  0,  2,  1,  0,  4,  3,  1,  4,  1,  4,  0,  4,  4,  1,\n",
       "        1,  1,  1,  3,  3,  2,  0,  3,  4,  2,  1,  2,  2,  4,  1,  1,  1,\n",
       "        0,  0,  4,  1,  1,  2,  0,  4,  0,  1,  2,  2,  3,  0,  4,  4,  1,\n",
       "        2,  4,  2,  3,  2,  1,  0,  1,  4,  4,  2,  4,  2,  0,  0,  3,  0,\n",
       "        4,  1,  3,  3,  0,  2,  3,  1,  3,  1,  4,  2,  3,  2,  0,  3,  1,\n",
       "        0,  3,  0,  2,  0,  2, -1,  4,  4,  0,  2,  3,  4,  0,  2,  3,  4,\n",
       "        3,  4,  1,  0,  4,  4,  2,  2], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2,  3,  4], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelIDs = np.unique(dbscan.labels_)\n",
    "labelIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIDs = np.array([0,  1,  2,  3,  4], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_montages(image_list, image_shape, montage_shape):\n",
    "    image_montages = []\n",
    "    montage_image = np.zeros(shape=(image_shape[1] * (montage_shape[1]), image_shape[0] * montage_shape[0], 3),\n",
    "                          dtype=np.uint8)\n",
    "    cursor_pos = [0, 0]\n",
    "    start_new_img = False\n",
    "    for img in image_list:\n",
    "        start_new_img = False\n",
    "        img = cv2.resize(img, image_shape)\n",
    "        montage_image[cursor_pos[1]:cursor_pos[1] + image_shape[1], cursor_pos[0]:cursor_pos[0] + image_shape[0]] = img\n",
    "        cursor_pos[0] += image_shape[0]  \n",
    "        if cursor_pos[0] >= montage_shape[0] * image_shape[0]:\n",
    "            cursor_pos[1] += image_shape[1]  \n",
    "            cursor_pos[0] = 0\n",
    "            if cursor_pos[1] >= montage_shape[1] * image_shape[1]:\n",
    "                cursor_pos = [0, 0]\n",
    "                image_montages.append(montage_image)\n",
    "\n",
    "                montage_image = np.zeros(shape=(image_shape[1] * (montage_shape[1]), image_shape[0] * montage_shape[0], 3),\n",
    "                                      dtype=np.uint8)\n",
    "                start_new_img = True\n",
    "    if start_new_img is False:\n",
    "        image_montages.append(montage_image)  \n",
    "    return image_montages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   3   7   9  11  13  14  16  20  23  30  40  51  52  57  59  64\n",
      "  74  81  82  84  89  99 102 104 106 111 115 122]\n",
      "[  2   6  12  18  22  26  28  33  34  35  36  44  48  49  50  54  55  60\n",
      "  67  73  75  86  92  94 101 121]\n",
      "[  4   8  17  21  39  43  45  46  56  61  62  68  70  72  78  80  90  96\n",
      "  98 105 107 112 116 125 126]\n",
      "[  5  10  25  37  38  41  63  71  83  87  88  91  93  97 100 103 113 117\n",
      " 119]\n",
      "[ 15  19  24  27  29  31  32  42  47  53  58  65  66  69  76  77  79  85\n",
      "  95 109 110 114 118 120 123 124]\n"
     ]
    }
   ],
   "source": [
    "for labelID in labelIDs:\n",
    "    idxs = np.where(dbscan.labels_ == labelID)[0]\n",
    "    print (idxs)\n",
    "    np.random.choice(idxs,size=min(25,len(idxs)))\n",
    "    \n",
    "    faces = []\n",
    "    \n",
    "    for i in idxs:\n",
    "        image = cv2.imread(data[i]['imagePath'])\n",
    "        (top,right,bottom,left) = data[i]['loc']\n",
    "        face = image[top:bottom,left:right]\n",
    "        face = cv2.resize(face,(96,96))\n",
    "        faces.append(face)\n",
    "    montage = build_montages(faces,(96,96),(5,5))[0]\n",
    "    cv2.imshow('res',montage)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
